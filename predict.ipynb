{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import numpy as np\n",
    "from data.utils import get_magnitude, get_audio_from_magnitude\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from getmodel import get_model\n",
    "\n",
    "import sounddevice as sd\n",
    "import IPython.display as ipd\n",
    "import copy\n",
    "import time \n",
    "from pystoi import stoi\n",
    "from pesq import pesq\n",
    "\n",
    "def predict_waveform(audio, sr, length_seconds, model):\n",
    "    total_samples = audio.shape[1]\n",
    "    segment_length = sr * length_seconds\n",
    "    n_segments = int(np.ceil(audio.shape[1] / segment_length))\n",
    "\n",
    "    totalInferenceTime = 0\n",
    "    output_segments = {\"clean\": [], \"noise\": []}\n",
    "    for i in range(n_segments):\n",
    "        # print(f\"Processing segment {i+1}/{n_segments}\")\n",
    "        if audio.shape[1] >= (i + 1) * segment_length:\n",
    "            seg_audio = audio[:, i * segment_length : (i + 1) * segment_length]\n",
    "        else:\n",
    "            seg_audio = torch.zeros([1, segment_length])\n",
    "            seg_audio[:, 0 : audio.shape[1] - i * segment_length] = audio[:, i * segment_length :]\n",
    "\n",
    "        seg_audio = seg_audio.unsqueeze(0)\n",
    "\n",
    "        start_time = time.time()\n",
    "        out_sources = model(seg_audio)  # Use the model\n",
    "        end_time = time.time()\n",
    "        print(\"Time taken for inference: \", end_time - start_time)\n",
    "        totalInferenceTime += end_time - start_time\n",
    "        \n",
    "        out_sources = out_sources.squeeze()\n",
    "        out_sources = out_sources.cpu().detach()\n",
    "\n",
    "        clean_audio = out_sources[0:1, :]\n",
    "        noise_audio = out_sources[1:2, :]\n",
    "\n",
    "        # Append the obtained segments for each source into a list\n",
    "        output_segments[\"clean\"].append(clean_audio)\n",
    "        output_segments[\"noise\"].append(noise_audio)\n",
    "\n",
    "    # Concatenate along time dimension to obtain the full audio\n",
    "    clean_output = torch.cat(output_segments[\"clean\"], dim=1)\n",
    "    noise_output = torch.cat(output_segments[\"noise\"], dim=1)\n",
    "\n",
    "    print(\"Total inference time: \", totalInferenceTime)\n",
    "    return clean_output[:, 0:total_samples], noise_output[:, 0:total_samples]\n",
    "\n",
    "\n",
    "def predict_waveform_withTime(audio, sr, length_seconds, model):\n",
    "    total_samples = audio.shape[1]\n",
    "    segment_length = sr * length_seconds\n",
    "    n_segments = int(np.ceil(audio.shape[1] / segment_length))\n",
    "\n",
    "    output_segments = {\"clean\": [], \"noise\": []}\n",
    "    totalInferenceTime = 0\n",
    "    for i in range(n_segments):\n",
    "        # print(f\"Processing segment {i+1}/{n_segments}\")\n",
    "        if audio.shape[1] >= (i + 1) * segment_length:\n",
    "            seg_audio = audio[:, i * segment_length : (i + 1) * segment_length]\n",
    "        else:\n",
    "            seg_audio = torch.zeros([1, segment_length])\n",
    "            seg_audio[:, 0 : audio.shape[1] - i * segment_length] = audio[:, i * segment_length :]\n",
    "\n",
    "        seg_audio = seg_audio.unsqueeze(0)\n",
    "\n",
    "        start_time = time.time()\n",
    "        out_sources = model(seg_audio)  # Use the model\n",
    "        end_time = time.time()\n",
    "        totalInferenceTime += end_time - start_time\n",
    "        # print(\"Time taken for inference: \", end_time - start_time)\n",
    "        \n",
    "        out_sources = out_sources.squeeze()\n",
    "        out_sources = out_sources.cpu().detach()\n",
    "\n",
    "        clean_audio = out_sources[0:1, :]\n",
    "        noise_audio = out_sources[1:2, :]\n",
    "\n",
    "        # Append the obtained segments for each source into a list\n",
    "        output_segments[\"clean\"].append(clean_audio)\n",
    "        output_segments[\"noise\"].append(noise_audio)\n",
    "\n",
    "    # Concatenate along time dimension to obtain the full audio\n",
    "    clean_output = torch.cat(output_segments[\"clean\"], dim=1)\n",
    "    noise_output = torch.cat(output_segments[\"noise\"], dim=1)\n",
    "\n",
    "    return clean_output[:, 0:total_samples], noise_output[:, 0:total_samples], totalInferenceTime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load in Trained Model and any noisy speech testing file here, then run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these to test on any file with any model\n",
    "filepath = \"datasets/Test/26-495-0047\"\n",
    "tarFile = \"LearningRate001\"\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "# File to be denoised\n",
    "inputFilePath = f'{filepath}.wav'\n",
    "outputFilePath = f'{filepath}({tarFile}).wav'\n",
    "\n",
    "model = \"ConvTasNet\"\n",
    "checkpointName = f'{tarFile}.tar'\n",
    "length = 4\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "# Getting the trained model\n",
    "training_utils_dict = get_model(model)\n",
    "trainedModel = training_utils_dict[\"model\"]\n",
    "data_mode = training_utils_dict[\"data_mode\"]\n",
    "# loss_fn = training_utils_dict[\"loss_fn\"]\n",
    "# loss_mode = training_utils_dict[\"loss_mode\"]\n",
    "\n",
    "assert os.path.isfile(checkpointName) and checkpointName.endswith(\n",
    "    \".tar\"\n",
    "), \"The specified checkpoint_name is not a valid checkpoint\"\n",
    "checkpoint = torch.load(checkpointName,map_location=torch.device('cpu'))\n",
    "trainedModel.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "trainedModel = trainedModel.to(device)\n",
    "trainedModel.eval()\n",
    "print(f\"Model loaded from checkpoint: {checkpointName}\")\n",
    "\n",
    "\n",
    "def bestModelTest(model = model, checkpointName = checkpointName, inputFilePath = inputFilePath, outputFilePath = outputFilePath, length = length, device = device):\n",
    " \n",
    "    extensions = (\".mp3\", \".wav\", \".flac\")\n",
    "    assert os.path.isfile(inputFilePath) and inputFilePath.endswith(\n",
    "        extensions\n",
    "    ), f\"Input file cannot be loaded. Either it does not exist or has a wrong extension. Allowed extensions {extensions}\"\n",
    "\n",
    "    audio, sr = torchaudio.load(inputFilePath)\n",
    "    if sr != 16000:\n",
    "        audio = torchaudio.transforms.Resample(sr, 16000)(audio)\n",
    "        sr = 16000\n",
    "\n",
    "    audio /= audio.abs().max()\n",
    "\n",
    "    if data_mode in [\"time\"]:\n",
    "        clean_output, noise_output = predict_waveform(audio.to(device), sr, length, model)\n",
    "\n",
    "    # Normalization wrt mixture\n",
    "    clean_output /= audio.abs().max()#clean_output.abs().max()\n",
    "    noise_output /= audio.abs().max()#noise_output.abs().max()\n",
    "\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(\n",
    "        audio[\n",
    "            0,\n",
    "        ]\n",
    "    )\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(\n",
    "        clean_output[\n",
    "            0,\n",
    "        ]\n",
    "    )\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(\n",
    "        noise_output[\n",
    "            0,\n",
    "        ]\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    output_name, ext = os.path.splitext(outputFilePath)\n",
    "\n",
    "    torchaudio.save(f\"{output_name}_clean{ext}\", clean_output, sr)\n",
    "    torchaudio.save(f\"{output_name}_noise{ext}\", noise_output, sr)\n",
    "\n",
    "    return audio, clean_output, noise_output,sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy,clean,_,sr= bestModelTest(model=trainedModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noisy input audio\n",
    "ipd.Audio(noisy, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denoised audio\n",
    "ipd.Audio(clean, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the above trained model to a pytorch mobile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "training_utils_dict = get_model(model)\n",
    "# training_utils_dict = copy.deepcopy(get_model(model))\n",
    "\n",
    "trainedModel = training_utils_dict[\"model\"]\n",
    "data_mode = training_utils_dict[\"data_mode\"]\n",
    "\n",
    "checkpoint = torch.load(checkpointName,map_location=torch.device('cpu'))\n",
    "trainedModel.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "scripted_module = torch.jit.script(trainedModel)\n",
    "optimized_scripted_module = optimize_for_mobile(scripted_module)\n",
    "optimized_scripted_module._save_for_lite_interpreter(f'./{tarFile}.ptl')\n",
    "print(f'Pytorch mobile model saved as {tarFile}.ptl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with the pytorch mobile model and same testing noisy file as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileModel = torch.jit.load(f'{tarFile}.ptl')\n",
    "mobileModel = mobileModel.to(device)\n",
    "mobileModel.eval()\n",
    "print(f'Model loaded from tar file: {tarFile}.ptl')\n",
    "\n",
    "extensions = (\".mp3\", \".wav\", \".flac\")\n",
    "assert os.path.isfile(inputFilePath) and inputFilePath.endswith(\n",
    "    extensions\n",
    "), f\"Input file cannot be loaded. Either it does not exist or has a wrong extension. Allowed extensions {extensions}\"\n",
    "\n",
    "mobile_audio, sr = torchaudio.load(inputFilePath)\n",
    "if sr != 16000:\n",
    "    mobile_audio = torchaudio.transforms.Resample(sr, 16000)(mobile_audio)\n",
    "    sr = 16000\n",
    "\n",
    "mobile_audio /= mobile_audio.abs().max()\n",
    "\n",
    "# Just consider it time here\n",
    "mobile_clean_output, mobile_noise_output = predict_waveform(mobile_audio.to(device), sr, length, mobileModel)\n",
    "\n",
    "# Normalization wrt mixture\n",
    "mobile_clean_output /= mobile_audio.abs().max()#clean_output.abs().max()\n",
    "mobile_noise_output /= mobile_audio.abs().max()#noise_output.abs().max()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(\n",
    "    mobile_audio[\n",
    "        0,\n",
    "    ]\n",
    ")\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(\n",
    "    mobile_clean_output[\n",
    "        0,\n",
    "    ]\n",
    ")\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(\n",
    "    mobile_noise_output[\n",
    "        0,\n",
    "    ]\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "output_name, ext = os.path.splitext(outputFilePath)\n",
    "\n",
    "torchaudio.save(f\"{output_name}_clean_mobile{ext}\", mobile_clean_output, sr)\n",
    "torchaudio.save(f\"{output_name}_noise_mobile{ext}\", mobile_noise_output, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Denoised audio\n",
    "ipd.Audio(mobile_clean_output, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Different SNR ranges with longer audio files than training duration\n",
    "1. Making inferences on multiple noisy speech files\n",
    "2. Getting the average pesq and estoi scores for the noisy speech files within their respective SNR ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferWithModel(mobileModel, inputTensor, sr, length,sources):\n",
    "    # Just consider it time here\n",
    "    mobile_clean_output, mobile_noise_output, totalInferenceTime = predict_waveform_withTime(inputTensor.to(device), sr, length, mobileModel)\n",
    "\n",
    "    # Normalization wrt mixture\n",
    "    mobile_clean_output /= mobile_audio.abs().max()#clean_output.abs().max()\n",
    "    mobile_noise_output /= mobile_audio.abs().max()#noise_output.abs().max()\n",
    "\n",
    "    mobile_clean_output = np.squeeze(mobile_clean_output)\n",
    "    # print(f'sources[0].shape: {sources[0].shape}')\n",
    "    # print(f'mobile_clean_output.shape: {mobile_clean_output.shape}')\n",
    "    pesq_score = pesq(fs = sr,ref = sources[0].numpy(),deg = mobile_clean_output.numpy())\n",
    "    estoi_score = stoi(x=sources[0].numpy(),y = mobile_clean_output.numpy(),fs_sig= sr,extended=True)\n",
    "\n",
    "    return pesq_score, estoi_score, totalInferenceTime      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_rate=0.05\n",
    "# min_snr=-20\n",
    "# max_snr=-10\n",
    "sr = 16000\n",
    "length = 12\n",
    "num_of_samples_per_snr = 50\n",
    "\n",
    "snr_ranges = [(-30,-20),(-20,-10),(-10,0),(0,10),(10,20),(20,30)]\n",
    "\n",
    "from data import AudioDirectoryDataset, NoiseMixerDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "clean_dataset_path = f'datasets/Validation/cleanSliced{length}sec'\n",
    "noise_dataset_path = f'datasets/Validation/noisySliced{length}sec'\n",
    "\n",
    "all_pesqScores_before = []\n",
    "all_estoiScores_before = []\n",
    "all_pesqScores = []\n",
    "all_estoiScores = []\n",
    "all_inferenceTimes= []\n",
    "\n",
    "\n",
    "all_pesqScores_mob = []\n",
    "all_estoiScores_mob = []\n",
    "all_inferenceTimes_mob= []\n",
    "\n",
    "for min_snr,max_snr in snr_ranges:\n",
    "    print(f'Mixing {length} seconds clean and noisy with SNR range ({min_snr}, {max_snr}) with keepRate of {keep_rate}')\n",
    "    train_clean_dataset = AudioDirectoryDataset(root=clean_dataset_path,keep_rate=keep_rate)\n",
    "    train_noise_dataset = AudioDirectoryDataset(root=noise_dataset_path,keep_rate=keep_rate)\n",
    "    train_data = NoiseMixerDataset(\n",
    "        clean_dataset=train_clean_dataset, noise_dataset=train_noise_dataset, min_snr=min_snr, max_snr=max_snr\n",
    "    )\n",
    "\n",
    "    print(f\"Dataset size: {len(train_data)}\")\n",
    "    print(f'Samples used : {num_of_samples_per_snr}')\n",
    "    mixtureT, sourcesT = train_data[0]\n",
    "\n",
    "    # Just to check if the audio sample is correct\n",
    "    # torchaudio.save(f'datasets/testOnAndroidAsWell/MixtureSNR({min_snr},{max_snr}){ext}', sourcesT, sr)\n",
    "\n",
    "    pesqScores_before = []\n",
    "    estoiScores_before = []\n",
    "\n",
    "    pesqScores = []\n",
    "    estoiScores = []\n",
    "    inferenceTimes = []\n",
    "    \n",
    "    pesqScores_mob = []\n",
    "    estoiScores_mob = []\n",
    "    inferenceTimes_mob = []\n",
    "\n",
    "    for i, (mixture, sources) in  enumerate(train_data):\n",
    "        # print(f'Train Element {i+1}:')\n",
    "        if i==0 : print(mixture.shape, sources.shape)\n",
    "        # mixture, [clean, noise]\n",
    "        # 20 samples taken\n",
    "        if(i == num_of_samples_per_snr): break\n",
    "       \n",
    "        # if i==10: print(f'Element {i} ::> PESQ Score: {pesqScore} and ESTOI Score: {estoiScore}')\n",
    "        torchaudio.save(f'datasets/testOnAndroidAsWell2/{min_snr}_{max_snr}/noisySpeechSample_{i}_{ext}', sourcesT, sr)\n",
    "\n",
    "        pesq_score_before = pesq(fs = sr,ref = sources[0].numpy(),deg = np.squeeze(mixture.numpy()))\n",
    "        estoi_score_before = stoi(x=sources[0].numpy(),y = np.squeeze(mixture.numpy()),fs_sig= sr,extended=True)\n",
    "        pesqScores_before.append(pesq_score_before)\n",
    "        estoiScores_before.append(estoi_score_before)\n",
    "\n",
    "        pesqScore,estoiScore,totalInferenceTime = inferWithModel(trainedModel, mixture, sr, length, sources)\n",
    "        pesqScore_mob,estoiScore_mob,totalInferenceTime_mob = inferWithModel(mobileModel, mixture, sr, length, sources)\n",
    "       \n",
    "        # Inside specific SNR range\n",
    "        pesqScores.append(pesqScore)\n",
    "        estoiScores.append(estoiScore)\n",
    "        inferenceTimes.append(totalInferenceTime)\n",
    "\n",
    "        pesqScores_mob.append(pesqScore_mob)\n",
    "        estoiScores_mob.append(estoiScore_mob)\n",
    "        inferenceTimes_mob.append(totalInferenceTime_mob)\n",
    "\n",
    "        # For all SNR ranges\n",
    "    all_pesqScores.append(np.array(pesqScores))\n",
    "    all_estoiScores.append(np.array(estoiScores))\n",
    "    all_inferenceTimes.append(np.array(inferenceTimes))\n",
    "\n",
    "    all_pesqScores_mob.append(np.array(pesqScores_mob))\n",
    "    all_estoiScores_mob.append(np.array(estoiScores_mob))\n",
    "    all_inferenceTimes_mob.append(np.array(inferenceTimes_mob))\n",
    "\n",
    "    all_pesqScores_before.append(np.array(pesqScores_before))\n",
    "    all_estoiScores_before.append(np.array(estoiScores_before))\n",
    "\n",
    "    print(f'Average PESQ Score before: {np.mean(pesqScores_before)} and Average ESTOI Score before: {np.mean(estoiScores_before)}')\n",
    "    print(f'Average PESQ Score: {np.mean(pesqScores)} and Average ESTOI Score: {np.mean(estoiScores)} and Average Inference Time: {np.mean(inferenceTimes)}')\n",
    "\n",
    "print(f'Length of all_pesqScores: {len(all_pesqScores)}')\n",
    "print(f'Length of all_estoiScores: {len(all_estoiScores)}')\n",
    "print(f'Length of all_inferenceTimes: {len(all_inferenceTimes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(allPesqScores,allEstoiScores,allPesqScoresBefore,allEstoiScoresBefore,postFix = \"\"):\n",
    "    snr_ranges = [(-30,-20),(-20,-10),(-10,0),(0,10),(10,20),(20,30)]\n",
    "    mean_values = []\n",
    "    variance_values = []\n",
    "\n",
    "    ############################################################## PESQ\n",
    "    # Calculate mean and variance for each SNR range\n",
    "    for snr_range, data_array in zip(snr_ranges, allPesqScores):\n",
    "        mean_values.append(np.mean(data_array))\n",
    "        variance_values.append(np.var(data_array))\n",
    "\n",
    "    labels = [f'({snr_range[0]},{snr_range[1]})' for snr_range in snr_ranges]\n",
    "    # Plotting the histogram\n",
    "    plt.bar(range(len(snr_ranges)), mean_values, yerr=variance_values, capsize=5, tick_label=labels)\n",
    "    plt.xlabel('SNR Ranges')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title('PESQ: Mean and Variance (After Enhancement)')\n",
    "\n",
    "    for i, (mean_val, var_val) in enumerate(zip(mean_values, variance_values)):\n",
    "        plt.text(i, mean_val + 0.05, f'{mean_val:.2f}', ha='right', va='baseline', color = 'green')\n",
    "        plt.text(i, mean_val - 0.05, f'{var_val:.2f}', ha='left', va='top', color= 'yellow')\n",
    "\n",
    "    plt.savefig(f'after_enhancement_plot_pesq{postFix}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    mean_values_before = []\n",
    "    variance_values_before  = []\n",
    "    for snr_range, data_array in zip(snr_ranges, allPesqScoresBefore):\n",
    "        mean_values_before.append(np.mean(data_array))\n",
    "        variance_values_before.append(np.var(data_array))\n",
    "\n",
    "    # BEFORE ENHANCEMENT\n",
    "    # Plotting the histogram\n",
    "    plt.bar(range(len(snr_ranges)), mean_values_before, yerr=variance_values_before, capsize=5, tick_label=labels)\n",
    "    plt.xlabel('SNR Ranges')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title('PESQ: Mean and Variance (Before Enhancement)')\n",
    "\n",
    "    for i, (mean_val, var_val) in enumerate(zip(mean_values_before, variance_values_before)):\n",
    "        plt.text(i, mean_val + 0.05, f'{mean_val:.2f}', ha='right', va='baseline', color = 'green')\n",
    "        plt.text(i, mean_val - 0.05, f'{var_val:.2f}', ha='left', va='top', color= 'yellow')\n",
    "\n",
    "    plt.savefig(f'before_enhancement_plot_pesq{postFix}.png')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # Plotting the combined histogram for mean values\n",
    "    bar_width = 0.35  # Adjust the width of the bars\n",
    "    bar_positions_after = np.arange(len(snr_ranges))\n",
    "    bar_positions_before = bar_positions_after + bar_width  # Adjust positions for the second set of bars\n",
    "\n",
    "    # Bar plot for mean values after enhancement (blue)\n",
    "    plt.bar(bar_positions_after, mean_values, width=bar_width, label='After Enhancement', color='green', alpha=0.7)\n",
    "\n",
    "    # Bar plot for mean values before enhancement (green)\n",
    "    plt.bar(bar_positions_before, mean_values_before, width=bar_width, label='Before Enhancement', color='blue', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('SNR Ranges')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title('PESQ: Mean Comparison')\n",
    "    plt.xticks(bar_positions_after + bar_width / 2, labels)  # Adjust the x-axis tick positions\n",
    "    plt.legend()\n",
    "\n",
    "    # Adding text annotations for mean values\n",
    "    for i, (mean_val_after, mean_val_before) in enumerate(zip(mean_values, mean_values_before)):\n",
    "        plt.text(bar_positions_after[i], mean_val_after + 0.05, f'{mean_val_after:.2f}', ha='center', va='bottom', color='green')\n",
    "        plt.text(bar_positions_before[i], mean_val_before + 0.05, f'{mean_val_before:.2f}', ha='center', va='bottom', color='blue')\n",
    "\n",
    "    # Save the combined plot\n",
    "    plt.ylim(0,3.5)\n",
    "    plt.savefig(f'combined_plot_pesq{postFix}.png')\n",
    "\n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    ############################################################## ESTOI\n",
    "\n",
    "    mean_values = []\n",
    "    variance_values = []\n",
    "    # Calculate mean and variance for each SNR range\n",
    "    for snr_range, data_array in zip(snr_ranges, allEstoiScores):\n",
    "        mean_values.append(np.mean(data_array))\n",
    "        variance_values.append(np.var(data_array))\n",
    "\n",
    "    labels = [f'({snr_range[0]},{snr_range[1]})' for snr_range in snr_ranges]\n",
    "    # Plotting the histogram\n",
    "    plt.bar(range(len(snr_ranges)), mean_values, yerr=variance_values, capsize=5, tick_label=labels)\n",
    "    plt.xlabel('SNR Ranges')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title('ESTOI: Mean and Variance (After Enhancement)')\n",
    "\n",
    "    for i, (mean_val, var_val) in enumerate(zip(mean_values, variance_values)):\n",
    "        plt.text(i, mean_val + 0.05, f'{mean_val:.2f}', ha='right', va='baseline', color = 'green')\n",
    "        plt.text(i, mean_val - 0.05, f'{var_val:.2f}', ha='left', va='top', color= 'yellow')\n",
    "\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.savefig(f'after_enhancement_plot_estoi{postFix}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    mean_values_before = []\n",
    "    variance_values_before  = []\n",
    "    for snr_range, data_array in zip(snr_ranges, allEstoiScoresBefore):\n",
    "        mean_values_before.append(np.mean(data_array))\n",
    "        variance_values_before.append(np.var(data_array))\n",
    "\n",
    "    # BEFORE ENHANCEMENT\n",
    "    # Plotting the histogram\n",
    "    plt.bar(range(len(snr_ranges)), mean_values_before, yerr=variance_values_before, capsize=5, tick_label=labels)\n",
    "    plt.xlabel('SNR Ranges')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title('ESTOI: Mean and Variance (Before Enhancement)')\n",
    "\n",
    "    for i, (mean_val, var_val) in enumerate(zip(mean_values_before, variance_values_before)):\n",
    "        plt.text(i, mean_val + 0.05, f'{mean_val:.2f}', ha='right', va='baseline', color = 'green')\n",
    "        plt.text(i, mean_val - 0.05, f'{var_val:.2f}', ha='left', va='top', color= 'yellow')\n",
    "\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.savefig(f'before_enhancement_plot_estoi{postFix}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Plotting the combined histogram for mean values\n",
    "    bar_width = 0.35  # Adjust the width of the bars\n",
    "    bar_positions_after = np.arange(len(snr_ranges))\n",
    "    bar_positions_before = bar_positions_after + bar_width  # Adjust positions for the second set of bars\n",
    "\n",
    "    # Bar plot for mean values after enhancement (blue)\n",
    "    plt.bar(bar_positions_after, mean_values, width=bar_width, label='After Enhancement', color='green', alpha=0.7)\n",
    "\n",
    "    # Bar plot for mean values before enhancement (green)\n",
    "    plt.bar(bar_positions_before, mean_values_before, width=bar_width, label='Before Enhancement', color='blue', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('SNR Ranges')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title('ESTOI: Mean Comparison')\n",
    "    plt.xticks(bar_positions_after + bar_width / 2, labels)  # Adjust the x-axis tick positions\n",
    "    plt.legend()\n",
    "\n",
    "    # Adding text annotations for mean values\n",
    "    for i, (mean_val_after, mean_val_before) in enumerate(zip(mean_values, mean_values_before)):\n",
    "        plt.text(bar_positions_after[i], mean_val_after + 0.05, f'{mean_val_after:.2f}', ha='center', va='bottom', color='green')\n",
    "        plt.text(bar_positions_before[i], mean_val_before + 0.05, f'{mean_val_before:.2f}', ha='center', va='bottom', color='blue')\n",
    "\n",
    "    plt.ylim(0, 1.5)\n",
    "    # Save the combined plot\n",
    "    plt.savefig(f'combined_plot_estoi{postFix}.png')\n",
    "\n",
    "    # Show the combined plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparisonInferenceTimes(allPesqScores,allEstoiScores,allPesqScores_mob,allEstoiScores_mob,allInferenceTimes,allInferenceTimes_mob):\n",
    "    snr_ranges = [(-30,-20),(-20,-10),(-10,0),(0,10),(10,20),(20,30)]\n",
    "    # Plotting the combined histogram for mean values\n",
    "    mean_values_pesq_after = []\n",
    "    mean_values_estoi_after = []\n",
    "\n",
    "    mean_values_pesq_after_mob = []\n",
    "    mean_values_estoi_after_mob = []\n",
    "\n",
    "\n",
    "    # Calculate mean for each SNR range\n",
    "    for snr_range, data_array in zip(snr_ranges, allEstoiScores):\n",
    "        mean_values_estoi_after.append(np.mean(data_array))\n",
    "\n",
    "    for snr_range, data_array in zip(snr_ranges, allPesqScores):\n",
    "        mean_values_pesq_after.append(np.mean(data_array))\n",
    "\n",
    "    for snr_range, data_array in zip(snr_ranges, allEstoiScores_mob):\n",
    "        mean_values_estoi_after_mob.append(np.mean(data_array))\n",
    "    \n",
    "    for snr_range, data_array in zip(snr_ranges, allPesqScores_mob):\n",
    "        mean_values_pesq_after_mob.append(np.mean(data_array))\n",
    "\n",
    "\n",
    "    labels = [f'({snr_range[0]},{snr_range[1]})' for snr_range in snr_ranges]\n",
    "    \n",
    "    bar_width = 0.35  # Adjust the width of the bars\n",
    "    bar_positions_after = np.arange(len(snr_ranges))\n",
    "    bar_positions_after_mob = bar_positions_after + bar_width  # Adjust positions for the second set of bars\n",
    "\n",
    "    # Bar plot for mean values after enhancement (blue)\n",
    "    plt.bar(bar_positions_after, mean_values_pesq_after, width=bar_width, label='PC', color='blue', alpha=0.7)\n",
    "\n",
    "    # Bar plot for mean values before enhancement (green)\n",
    "    plt.bar(bar_positions_after_mob, mean_values_pesq_after_mob, width=bar_width, label='Mobile', color='orange', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('SNR Ranges')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title('PESQ: PC vs Mobile for Denoised Output')\n",
    "    plt.xticks(bar_positions_after + bar_width / 2, labels)  # Adjust the x-axis tick positions\n",
    "    plt.legend()\n",
    "\n",
    "    # Adding text annotations for mean values\n",
    "    for i, (mean_val_after, mean_val_after_mob) in enumerate(zip(mean_values_pesq_after, mean_values_pesq_after_mob)):\n",
    "        print(f'{mean_val_after}')\n",
    "        print(f'{mean_val_after_mob}')\n",
    "        plt.text(bar_positions_after[i], mean_val_after + 0.05, f'{mean_val_after:.2f}', ha='center', va='bottom', color='blue')\n",
    "        plt.text(bar_positions_after_mob[i], mean_val_after_mob + 0.05, f'{mean_val_after_mob:.2f}', ha='center', va='bottom', color='orange')\n",
    "\n",
    "    plt.ylim(0, 3.5)\n",
    "    # Save the combined plot\n",
    "    plt.savefig(f'ModelComparison_PESQ.png')\n",
    "\n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    bar_width = 0.35  # Adjust the width of the bars\n",
    "    bar_positions_after = np.arange(len(snr_ranges))\n",
    "    bar_positions_after_mob = bar_positions_after + bar_width  # Adjust positions for the second set of bars\n",
    "\n",
    "    # Bar plot for mean values after enhancement (blue)\n",
    "    plt.bar(bar_positions_after, mean_values_estoi_after, width=bar_width, label='PC', color='blue', alpha=0.7)\n",
    "\n",
    "    # Bar plot for mean values before enhancement (green)\n",
    "    plt.bar(bar_positions_after_mob, mean_values_estoi_after_mob, width=bar_width, label='Mobile', color='orange', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('SNR Ranges')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title('ESTOI: PC vs Mobile for Denoised Output')\n",
    "    plt.xticks(bar_positions_after + bar_width / 2, labels)  # Adjust the x-axis tick positions\n",
    "    plt.legend()\n",
    "\n",
    "    # Adding text annotations for mean values\n",
    "    for i, (mean_val_after, mean_val_after_mob) in enumerate(zip(mean_values_estoi_after, mean_values_estoi_after_mob)):\n",
    "        plt.text(bar_positions_after[i], mean_val_after + 0.05, f'{mean_val_after:.2f}', ha='center', va='bottom', color='blue')\n",
    "        plt.text(bar_positions_after_mob[i], mean_val_after_mob + 0.05, f'{mean_val_after_mob:.2f}', ha='center', va='bottom', color='orange')\n",
    "\n",
    "    plt.ylim(0, 1.5)\n",
    "    # Save the combined plot\n",
    "    plt.savefig(f'ModelComparison_ESTOI.png')\n",
    "\n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "    # Flatten the arrays\n",
    "    flatTimesPC = np.array(allInferenceTimes).flatten()\n",
    "    flatTimes_mob = np.array(allInferenceTimes_mob).flatten()\n",
    "\n",
    "    # Calculate mean and variance\n",
    "    mean_pc = np.mean(flatTimesPC)\n",
    "    mean_mob = np.mean(flatTimes_mob)\n",
    "    \n",
    "\n",
    "    # Plotting\n",
    "    labels = ['PC', 'Mobile']\n",
    "    means = [mean_pc, mean_mob]\n",
    "\n",
    "    plt.bar(labels, means, color=['blue', 'orange'])\n",
    "    plt.ylabel('Mean Inference Time')\n",
    "    plt.title('Comparison of Inference Times')\n",
    "\n",
    "    # Adding text annotations on top of the bars\n",
    "    for i, mean_value in enumerate(means):\n",
    "        plt.text(i, mean_value + 0.1, f'{mean_value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.ylim(0,5)\n",
    "    plt.savefig(f'ModelComparison_InferenceTimes.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotResults(all_pesqScores,all_estoiScores,all_pesqScores_before,all_estoiScores_before,\"PC2\")\n",
    "plotResults(all_pesqScores_mob,all_estoiScores_mob,all_pesqScores_before,all_estoiScores_before,\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonInferenceTimes(all_pesqScores,all_estoiScores,all_pesqScores_mob,all_estoiScores_mob,all_inferenceTimes,all_inferenceTimes_mob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coinpp-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
